{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stepik_Ml.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bvm84/open_colab_ml/blob/master/Stepik_Ml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VISPwoBjgf66",
        "colab_type": "code",
        "outputId": "b72d572a-80e1-450b-c00d-3aea3fea5bf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import os\n",
        "import datetime as dt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pandas as pd\n",
        "from sklearn import tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "% matplotlib inline\n",
        "np.random.seed(0)\n",
        "# print(os.getcwd())\n",
        "'''\n",
        "students_performance = pd.read_csv('StudentsPerformance.csv')\n",
        "print(students_performance.columns)\n",
        "# print(students_performance.head)\n",
        "standart_lunch = students_performance[(students_performance['lunch'] == 'standard')]\n",
        "free_lunch = students_performance[(students_performance['lunch'] == 'free/reduced')]\n",
        "print(standart_lunch['math score'].mean())\n",
        "print(standart_lunch['reading score'].mean())\n",
        "print(standart_lunch['writing score'].mean())\n",
        "print(free_lunch['math score'].mean())\n",
        "print(free_lunch['reading score'].mean())\n",
        "print(free_lunch['writing score'].mean())\n",
        "print(standart_lunch['math score'].std())\n",
        "print(standart_lunch['reading score'].std())\n",
        "print(standart_lunch['writing score'].std())\n",
        "print(free_lunch['math score'].std())\n",
        "print(free_lunch['reading score'].std())\n",
        "print(free_lunch['writing score'].std())\n",
        "# standart_lunch.filter(like='score', axis = 1)\n",
        "# standart_lunch.select_dtypes(include='number')\n",
        "\n",
        "# students_performance.groupby('gender').mean()\n",
        "# students_performance.groupby('gender').aggregate({'math score': 'mean'})\n",
        "students_performance.groupby('gender', as_index=False) \\\n",
        "    .aggregate({'math score': 'mean'}).rename(columns = {'math score': 'mean math score'})\n",
        "students_performance.groupby(['gender', 'lunch'], as_index=False) \\\n",
        "    .aggregate({'math score': 'mean'}).rename(columns = {'math score': 'mean math score'})\n",
        "\n",
        "mean_scores = students_performance.groupby(['gender', 'race/ethnicity']) \\\n",
        "    .aggregate({'math score': 'mean'}).rename(columns = {'math score': 'mean math score'})\n",
        "# mean_scores\n",
        "mean_scores.loc[('female', 'group A')]\n",
        "students_performance.sort_values(['gender', 'math score'], ascending=False).groupby('gender').head()\n",
        "students_performance.columns = [x.replace(\" \", \"_\") for x in students_performance.columns]\n",
        "students_performance['total_score'] = students_performance.math_score \\\n",
        "    + students_performance.reading_score + students_performance.writing_score\n",
        "students_performance = students_performance.assign(total_score_log = np.log(students_performance.total_score))\n",
        "students_performance.head()\n",
        "dota_df = pd.read_csv('dota_hero_stats.csv')\n",
        "print(dota_df.head())\n",
        "print(dota_df.columns)\n",
        "print(dota_df['legs'].value_counts(sort=True, dropna=False))\n",
        "\n",
        "acc_df = pd.read_csv('accountancy.csv')\n",
        "print(acc_df.head())\n",
        "print(acc_df.columns)\n",
        "print(acc_df.groupby(['Type', 'Executor']).aggregate({'Salary': 'mean'}))\n",
        "\n",
        "dota_df = pd.read_csv('dota_hero_stats.csv')\n",
        "# print(dota_df.head())\n",
        "# print(dota_df.columns)\n",
        "print(dota_df.groupby(['attack_type', 'primary_attr']).count())\n",
        "# print(dota_df.groupby(['attack_type', 'primary_attr']).head())\n",
        "# print(dota_df.groupby(['attack_type', 'primary_attr']).describe())\n",
        "algae_df = pd.read_csv('algae.csv')\n",
        "print(algae_df.head())\n",
        "print(algae_df.columns)\n",
        "# print(algae_df.groupby(['genus']).mean())\n",
        "# print(algae_df.groupby(['genus']).filter(like=['Fucus'], axis=1).head())\n",
        "# print(algae_df.groupby(['genus']).agg(np.mean).round(decimals=2))\n",
        "# print(algae_df.groupby(['genus', 'alanin']).agg(np.min).round(decimals=2))\n",
        "print(algae_df.groupby(['group']).agg('max')['sucrose']-algae_df.groupby(['group']).agg('min')['sucrose'])\n",
        "df = pd.read_csv(\"dataset_209770_6.txt\", sep=\" \")\n",
        "# df = DataFrame({'income': np.random.rand(100), 'time': np.arange(0,100)})\n",
        "print(df.head())\n",
        "print(df.columns)\n",
        "# df['income'].plot()\n",
        "sns.scatterplot(x=df[df.columns[0]], y=df[df.columns[1]])\n",
        "# df.income.plot()\n",
        "# sns.lineplot(data=df)\n",
        "# df.plot()\n",
        "# plt.plot(df.time, df.income)\n",
        "# df.plot(kind='line')\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"genome_matrix.csv\")\n",
        "print(df.head)\n",
        "print(df.columns)\n",
        "# df.drop()\n",
        "print(df[df.columns[1:]])\n",
        "#print(df.values)\n",
        "g = sns.heatmap(df[df.columns[1:]], cmap='viridis')\n",
        "g.xaxis.set_ticks_position('top')\n",
        "g.xaxis.set_tick_params(rotation=90)\n",
        "\n",
        "df = pd.read_json(\"heroes.json\")\n",
        "print(df.columns)\n",
        "df.role_count = df.roles.map(lambda x: len(eval('x')))\n",
        "print(df.role_count)\n",
        "df.role_count.hist()\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"iris.csv\")\n",
        "print(df.columns)\n",
        "print(df.head())\n",
        "\n",
        "for column in df:\n",
        "    if column != df.columns[0]:\n",
        "        g1 = sns.kdeplot(df[column])\n",
        "for column in df:\n",
        "    if column != df.columns[0]:\n",
        "        g2 = sns.distplot(df[column])\n",
        "sns.violinplot(x=None, y=df['petal length'])\n",
        "\n",
        "sns.pairplot(df, hue=\"species\")\n",
        "my_data = pd.DataFrame({'type': ['A', 'A', 'B', 'B'], 'value': [10, 14, 12, 23]})\n",
        "print(my_data)\n",
        "\n",
        "my_stat = pd.read_csv(\"my_stat.csv\")\n",
        "print(df.columns)\n",
        "print(df.head())\n",
        "\n",
        "subset_1 = df[['V1', 'V2']].iloc[:10]\n",
        "subset_2 = df[['V2', 'V4']].drop([0, 4], axis=0)\n",
        "print(subset_1)\n",
        "print(subset_2)\n",
        "\n",
        "\n",
        "subset_1 = df.query('V1 > 0 and V3 == \"A\"')\n",
        "subset_2 = df.query('V2 != 10 or V4 >= 1')\n",
        "print(subset_1)\n",
        "print(subset_2)\n",
        "\n",
        "df['V5'] = df['V1'] + df['V4']\n",
        "print(df.head())\n",
        "df['V6'] = np.log(df['V1'])\n",
        "print(df.head())\n",
        "\n",
        "\n",
        "my_stat = my_stat.rename(mapper={'V1': 'session_value', 'V2':'group', 'V3': 'time', 'V4': 'n_users'}, axis=1)\n",
        "\n",
        "my_stat['session_value'][0, 1] = np.NaN\n",
        "my_stat['n_users'][0, 1, 2, 3, 4, 5, 6, 7] = -100\n",
        "print(my_stat['session_value'].value_counts(dropna=False)) \n",
        "my_stat['session_value'].fillna(0, inplace=True)\n",
        "median = my_stat.query('n_users >= 0')['n_users'].median()\n",
        "# median = my_stat.query('n_users >= 0')['n_users']\n",
        "subset =  my_stat.query('n_users < 0')['n_users'].values\n",
        "my_stat['n_users'].replace(subset, median, inplace=True)\n",
        "print(subset)\n",
        "print(median)\n",
        "print(my_stat.head())\n",
        "\n",
        "print(my_stat.groupby('group', as_index=False).agg({'session_value': np.mean}).rename(index=str, columns={'session_value': 'mean_session_value'}))\n",
        "\n",
        "event_df = pd.read_csv(\"event_data_train.zip\", compression='zip')\n",
        "subs_df = pd.read_csv(\"submissions_data_train.zip\", compression='zip')\n",
        "\n",
        "print(event_df.columns)\n",
        "print(event_df.head())\n",
        "print(subs_df.columns)\n",
        "print(subs_df.head())\n",
        "print(event_df[0:500].groupby(['user_id', 'action']).agg('count'))\n",
        "print(subs_df[0:500].groupby(['user_id', 'submission_status']).agg('count'))\n",
        "'''\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nstudents_performance = pd.read_csv(\\'StudentsPerformance.csv\\')\\nprint(students_performance.columns)\\n# print(students_performance.head)\\nstandart_lunch = students_performance[(students_performance[\\'lunch\\'] == \\'standard\\')]\\nfree_lunch = students_performance[(students_performance[\\'lunch\\'] == \\'free/reduced\\')]\\nprint(standart_lunch[\\'math score\\'].mean())\\nprint(standart_lunch[\\'reading score\\'].mean())\\nprint(standart_lunch[\\'writing score\\'].mean())\\nprint(free_lunch[\\'math score\\'].mean())\\nprint(free_lunch[\\'reading score\\'].mean())\\nprint(free_lunch[\\'writing score\\'].mean())\\nprint(standart_lunch[\\'math score\\'].std())\\nprint(standart_lunch[\\'reading score\\'].std())\\nprint(standart_lunch[\\'writing score\\'].std())\\nprint(free_lunch[\\'math score\\'].std())\\nprint(free_lunch[\\'reading score\\'].std())\\nprint(free_lunch[\\'writing score\\'].std())\\n# standart_lunch.filter(like=\\'score\\', axis = 1)\\n# standart_lunch.select_dtypes(include=\\'number\\')\\n\\n# students_performance.groupby(\\'gender\\').mean()\\n# students_performance.groupby(\\'gender\\').aggregate({\\'math score\\': \\'mean\\'})\\nstudents_performance.groupby(\\'gender\\', as_index=False)     .aggregate({\\'math score\\': \\'mean\\'}).rename(columns = {\\'math score\\': \\'mean math score\\'})\\nstudents_performance.groupby([\\'gender\\', \\'lunch\\'], as_index=False)     .aggregate({\\'math score\\': \\'mean\\'}).rename(columns = {\\'math score\\': \\'mean math score\\'})\\n\\nmean_scores = students_performance.groupby([\\'gender\\', \\'race/ethnicity\\'])     .aggregate({\\'math score\\': \\'mean\\'}).rename(columns = {\\'math score\\': \\'mean math score\\'})\\n# mean_scores\\nmean_scores.loc[(\\'female\\', \\'group A\\')]\\nstudents_performance.sort_values([\\'gender\\', \\'math score\\'], ascending=False).groupby(\\'gender\\').head()\\nstudents_performance.columns = [x.replace(\" \", \"_\") for x in students_performance.columns]\\nstudents_performance[\\'total_score\\'] = students_performance.math_score     + students_performance.reading_score + students_performance.writing_score\\nstudents_performance = students_performance.assign(total_score_log = np.log(students_performance.total_score))\\nstudents_performance.head()\\ndota_df = pd.read_csv(\\'dota_hero_stats.csv\\')\\nprint(dota_df.head())\\nprint(dota_df.columns)\\nprint(dota_df[\\'legs\\'].value_counts(sort=True, dropna=False))\\n\\nacc_df = pd.read_csv(\\'accountancy.csv\\')\\nprint(acc_df.head())\\nprint(acc_df.columns)\\nprint(acc_df.groupby([\\'Type\\', \\'Executor\\']).aggregate({\\'Salary\\': \\'mean\\'}))\\n\\ndota_df = pd.read_csv(\\'dota_hero_stats.csv\\')\\n# print(dota_df.head())\\n# print(dota_df.columns)\\nprint(dota_df.groupby([\\'attack_type\\', \\'primary_attr\\']).count())\\n# print(dota_df.groupby([\\'attack_type\\', \\'primary_attr\\']).head())\\n# print(dota_df.groupby([\\'attack_type\\', \\'primary_attr\\']).describe())\\nalgae_df = pd.read_csv(\\'algae.csv\\')\\nprint(algae_df.head())\\nprint(algae_df.columns)\\n# print(algae_df.groupby([\\'genus\\']).mean())\\n# print(algae_df.groupby([\\'genus\\']).filter(like=[\\'Fucus\\'], axis=1).head())\\n# print(algae_df.groupby([\\'genus\\']).agg(np.mean).round(decimals=2))\\n# print(algae_df.groupby([\\'genus\\', \\'alanin\\']).agg(np.min).round(decimals=2))\\nprint(algae_df.groupby([\\'group\\']).agg(\\'max\\')[\\'sucrose\\']-algae_df.groupby([\\'group\\']).agg(\\'min\\')[\\'sucrose\\'])\\ndf = pd.read_csv(\"dataset_209770_6.txt\", sep=\" \")\\n# df = DataFrame({\\'income\\': np.random.rand(100), \\'time\\': np.arange(0,100)})\\nprint(df.head())\\nprint(df.columns)\\n# df[\\'income\\'].plot()\\nsns.scatterplot(x=df[df.columns[0]], y=df[df.columns[1]])\\n# df.income.plot()\\n# sns.lineplot(data=df)\\n# df.plot()\\n# plt.plot(df.time, df.income)\\n# df.plot(kind=\\'line\\')\\n\\n\\ndf = pd.read_csv(\"genome_matrix.csv\")\\nprint(df.head)\\nprint(df.columns)\\n# df.drop()\\nprint(df[df.columns[1:]])\\n#print(df.values)\\ng = sns.heatmap(df[df.columns[1:]], cmap=\\'viridis\\')\\ng.xaxis.set_ticks_position(\\'top\\')\\ng.xaxis.set_tick_params(rotation=90)\\n\\ndf = pd.read_json(\"heroes.json\")\\nprint(df.columns)\\ndf.role_count = df.roles.map(lambda x: len(eval(\\'x\\')))\\nprint(df.role_count)\\ndf.role_count.hist()\\n\\n\\ndf = pd.read_csv(\"iris.csv\")\\nprint(df.columns)\\nprint(df.head())\\n\\nfor column in df:\\n    if column != df.columns[0]:\\n        g1 = sns.kdeplot(df[column])\\nfor column in df:\\n    if column != df.columns[0]:\\n        g2 = sns.distplot(df[column])\\nsns.violinplot(x=None, y=df[\\'petal length\\'])\\n\\nsns.pairplot(df, hue=\"species\")\\nmy_data = pd.DataFrame({\\'type\\': [\\'A\\', \\'A\\', \\'B\\', \\'B\\'], \\'value\\': [10, 14, 12, 23]})\\nprint(my_data)\\n\\nmy_stat = pd.read_csv(\"my_stat.csv\")\\nprint(df.columns)\\nprint(df.head())\\n\\nsubset_1 = df[[\\'V1\\', \\'V2\\']].iloc[:10]\\nsubset_2 = df[[\\'V2\\', \\'V4\\']].drop([0, 4], axis=0)\\nprint(subset_1)\\nprint(subset_2)\\n\\n\\nsubset_1 = df.query(\\'V1 > 0 and V3 == \"A\"\\')\\nsubset_2 = df.query(\\'V2 != 10 or V4 >= 1\\')\\nprint(subset_1)\\nprint(subset_2)\\n\\ndf[\\'V5\\'] = df[\\'V1\\'] + df[\\'V4\\']\\nprint(df.head())\\ndf[\\'V6\\'] = np.log(df[\\'V1\\'])\\nprint(df.head())\\n\\n\\nmy_stat = my_stat.rename(mapper={\\'V1\\': \\'session_value\\', \\'V2\\':\\'group\\', \\'V3\\': \\'time\\', \\'V4\\': \\'n_users\\'}, axis=1)\\n\\nmy_stat[\\'session_value\\'][0, 1] = np.NaN\\nmy_stat[\\'n_users\\'][0, 1, 2, 3, 4, 5, 6, 7] = -100\\nprint(my_stat[\\'session_value\\'].value_counts(dropna=False)) \\nmy_stat[\\'session_value\\'].fillna(0, inplace=True)\\nmedian = my_stat.query(\\'n_users >= 0\\')[\\'n_users\\'].median()\\n# median = my_stat.query(\\'n_users >= 0\\')[\\'n_users\\']\\nsubset =  my_stat.query(\\'n_users < 0\\')[\\'n_users\\'].values\\nmy_stat[\\'n_users\\'].replace(subset, median, inplace=True)\\nprint(subset)\\nprint(median)\\nprint(my_stat.head())\\n\\nprint(my_stat.groupby(\\'group\\', as_index=False).agg({\\'session_value\\': np.mean}).rename(index=str, columns={\\'session_value\\': \\'mean_session_value\\'}))\\n\\nevent_df = pd.read_csv(\"event_data_train.zip\", compression=\\'zip\\')\\nsubs_df = pd.read_csv(\"submissions_data_train.zip\", compression=\\'zip\\')\\n\\nprint(event_df.columns)\\nprint(event_df.head())\\nprint(subs_df.columns)\\nprint(subs_df.head())\\nprint(event_df[0:500].groupby([\\'user_id\\', \\'action\\']).agg(\\'count\\'))\\nprint(subs_df[0:500].groupby([\\'user_id\\', \\'submission_status\\']).agg(\\'count\\'))\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsZGRWQPqOi3",
        "colab_type": "code",
        "outputId": "c0dc88fb-4db1-4e0f-db4d-06cf7deb7b0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''\n",
        "piv_t = pd.pivot_table(data=event_df[0:1000], index='user_id', columns='action', values='step_id', aggfunc='count').reset_index()\n",
        "print(piv_t)\n",
        "de_df = event_df.groupby(['user_id']).agg(list)\n",
        "print(type(de_df))\n",
        "de_df['range'] = de_df['timestamp'].apply(max) - de_df['timestamp'].apply(min)\n",
        "print(de_df['range'].sort_values())\n",
        "# print(de_df.loc[(slice(None), 'passed'), ])\n",
        "# print(subs_df.groupby(['user_id', 'submission_status']).agg('count'))\n",
        "subs_df[subs_df.submission_status == 'correct'].groupby('user_id').agg({'submission_status': 'count'}).sort_values(by=['submission_status'], ascending=False).head(20)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\npiv_t = pd.pivot_table(data=event_df[0:1000], index='user_id', columns='action', values='step_id', aggfunc='count').reset_index()\\nprint(piv_t)\\nde_df = event_df.groupby(['user_id']).agg(list)\\nprint(type(de_df))\\nde_df['range'] = de_df['timestamp'].apply(max) - de_df['timestamp'].apply(min)\\nprint(de_df['range'].sort_values())\\n# print(de_df.loc[(slice(None), 'passed'), ])\\n# print(subs_df.groupby(['user_id', 'submission_status']).agg('count'))\\nsubs_df[subs_df.submission_status == 'correct'].groupby('user_id').agg({'submission_status': 'count'}).sort_values(by=['submission_status'], ascending=False).head(20)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDr8eHXPzFAh",
        "colab_type": "code",
        "outputId": "af39adb5-c4e2-4a69-98c1-8e5b926713a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''\n",
        "event_df = pd.read_csv(\"cats.csv\")\n",
        "print(event_df)\n",
        "x = 4/10\n",
        "y = 6/10\n",
        "entr = -x*np.log2(x)-y*np.log2(y)\n",
        "print(entr)\n",
        "print(0.97-5/10*0.72)\n",
        "'''\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nevent_df = pd.read_csv(\"cats.csv\")\\nprint(event_df)\\nx = 4/10\\ny = 6/10\\nentr = -x*np.log2(x)-y*np.log2(y)\\nprint(entr)\\nprint(0.97-5/10*0.72)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M65dFiBieVJm",
        "colab_type": "code",
        "outputId": "ef3a61a1-ddc1-4c41-f528-9aa2e2a014ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''\n",
        "train_df = pd.read_csv(\"train_iris.csv\", index_col=0)\n",
        "print(train_df.columns)\n",
        "print(train_df.head())\n",
        "test_df = pd.read_csv(\"test_iris.csv\", index_col=0)\n",
        "print(test_df.columns)\n",
        "print(test_df.head())\n",
        "np.random.seed(0)\n",
        "x_train = train_df.drop('species', axis=1)\n",
        "y_train = train_df['species']\n",
        "x_test = test_df.drop('species', axis=1)\n",
        "y_test = test_df['species']\n",
        "train_scores = []\n",
        "test_scores = []\n",
        "for tree_length in range(1, 100):\n",
        "    clf = DecisionTreeClassifier(max_depth=tree_length)\n",
        "    clf.fit(x_train, y_train)\n",
        "    train_scores.append(clf.score(x_train, y_train))\n",
        "    test_scores.append(clf.score(x_test, y_test))\n",
        "result_df = DataFrame(data={'train_scores': train_scores, 'test_scores': test_scores})\n",
        "print(result_df.head())\n",
        "sns.lineplot(data=result_df)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ntrain_df = pd.read_csv(\"train_iris.csv\", index_col=0)\\nprint(train_df.columns)\\nprint(train_df.head())\\ntest_df = pd.read_csv(\"test_iris.csv\", index_col=0)\\nprint(test_df.columns)\\nprint(test_df.head())\\nnp.random.seed(0)\\nx_train = train_df.drop(\\'species\\', axis=1)\\ny_train = train_df[\\'species\\']\\nx_test = test_df.drop(\\'species\\', axis=1)\\ny_test = test_df[\\'species\\']\\ntrain_scores = []\\ntest_scores = []\\nfor tree_length in range(1, 100):\\n    clf = DecisionTreeClassifier(max_depth=tree_length)\\n    clf.fit(x_train, y_train)\\n    train_scores.append(clf.score(x_train, y_train))\\n    test_scores.append(clf.score(x_test, y_test))\\nresult_df = DataFrame(data={\\'train_scores\\': train_scores, \\'test_scores\\': test_scores})\\nprint(result_df.head())\\nsns.lineplot(data=result_df)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di4OCVFFntcG",
        "colab_type": "code",
        "outputId": "3768b2fe-de71-445b-c97b-abf50ea79ea0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''\n",
        "train_df = pd.read_csv(\"dogs_n_cats.csv\")\n",
        "print(len(train_df))\n",
        "print(train_df.columns)\n",
        "print(train_df.head())\n",
        "x = train_df.drop('Вид', axis=1)\n",
        "y = pd.get_dummies(train_df['Вид'])['котик']\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, shuffle=True)\n",
        "train_scores = []\n",
        "test_scores = []\n",
        "mean_cross_val_scores = []\n",
        "# print(y_train)\n",
        "for tree_length in range(1, 5):\n",
        "    clf = DecisionTreeClassifier(max_depth=tree_length, criterion='entropy')\n",
        "    mean_cross_val_score = cross_val_score(clf, x_train, y_train, cv=5).mean()\n",
        "    clf.fit(x_train, y_train)\n",
        "    train_scores.append(clf.score(x_train, y_train))\n",
        "    test_scores.append(clf.score(x_test, y_test))\n",
        "    mean_cross_val_scores.append(mean_cross_val_score)\n",
        "    tree.plot_tree(clf, feature_names=x_train.columns)\n",
        "scores = {'train_scores': train_scores, 'test_scores': test_scores, 'cv_srore':  mean_cross_val_scores}\n",
        "result_df = DataFrame(data=scores)\n",
        "print(result_df.head())\n",
        "sns.lineplot(data=result_df)\n",
        "print(train_df.query('Высота > 11.8').groupby('Вид').agg('count'))\n",
        "best_clf = DecisionTreeClassifier(max_depth=1, criterion='entropy')\n",
        "best_clf.fit(x_train, y_train)\n",
        "test_df = pd.read_json(\"dataset_209691_15.txt\")\n",
        "print(len(test_df))\n",
        "print(test_df.columns)\n",
        "print(test_df.head())\n",
        "neworder = train_df.columns\n",
        "df_test = test_df.reindex(columns=neworder)\n",
        "out = clf.predict(test_df)\n",
        "print(out)\n",
        "print(pd.Series(out).value_counts())\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ntrain_df = pd.read_csv(\"dogs_n_cats.csv\")\\nprint(len(train_df))\\nprint(train_df.columns)\\nprint(train_df.head())\\nx = train_df.drop(\\'Вид\\', axis=1)\\ny = pd.get_dummies(train_df[\\'Вид\\'])[\\'котик\\']\\nx_train, x_test, y_train, y_test = train_test_split(x, y, shuffle=True)\\ntrain_scores = []\\ntest_scores = []\\nmean_cross_val_scores = []\\n# print(y_train)\\nfor tree_length in range(1, 5):\\n    clf = DecisionTreeClassifier(max_depth=tree_length, criterion=\\'entropy\\')\\n    mean_cross_val_score = cross_val_score(clf, x_train, y_train, cv=5).mean()\\n    clf.fit(x_train, y_train)\\n    train_scores.append(clf.score(x_train, y_train))\\n    test_scores.append(clf.score(x_test, y_test))\\n    mean_cross_val_scores.append(mean_cross_val_score)\\n    tree.plot_tree(clf, feature_names=x_train.columns)\\nscores = {\\'train_scores\\': train_scores, \\'test_scores\\': test_scores, \\'cv_srore\\':  mean_cross_val_scores}\\nresult_df = DataFrame(data=scores)\\nprint(result_df.head())\\nsns.lineplot(data=result_df)\\nprint(train_df.query(\\'Высота > 11.8\\').groupby(\\'Вид\\').agg(\\'count\\'))\\nbest_clf = DecisionTreeClassifier(max_depth=1, criterion=\\'entropy\\')\\nbest_clf.fit(x_train, y_train)\\ntest_df = pd.read_json(\"dataset_209691_15.txt\")\\nprint(len(test_df))\\nprint(test_df.columns)\\nprint(test_df.head())\\nneworder = train_df.columns\\ndf_test = test_df.reindex(columns=neworder)\\nout = clf.predict(test_df)\\nprint(out)\\nprint(pd.Series(out).value_counts())\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jwlYl0ZTwOG",
        "colab_type": "code",
        "outputId": "3fda0e41-6bc3-4f44-fcfb-1da3927af0e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''\n",
        "df = pd.read_csv('train_data_tree.csv')\n",
        "print(df.columns)\n",
        "print(df.head())\n",
        "x = df.drop('num', axis=1)\n",
        "y = df['num']\n",
        "clf = DecisionTreeClassifier(criterion='entropy')\n",
        "clf.fit(x, y)\n",
        "tree.plot_tree(clf, feature_names=x.columns)\n",
        "l_node = clf.tree_.children_left[0]\n",
        "print(clf.tree_.children_left[0])\n",
        "print(clf.tree_.impurity)\n",
        "print(clf.tree_.n_node_samples)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndf = pd.read_csv('train_data_tree.csv')\\nprint(df.columns)\\nprint(df.head())\\nx = df.drop('num', axis=1)\\ny = df['num']\\nclf = DecisionTreeClassifier(criterion='entropy')\\nclf.fit(x, y)\\ntree.plot_tree(clf, feature_names=x.columns)\\nl_node = clf.tree_.children_left[0]\\nprint(clf.tree_.children_left[0])\\nprint(clf.tree_.impurity)\\nprint(clf.tree_.n_node_samples)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oo5VbdL7n_Dg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 0.996-((157/238)*0.903 + (81/238)*0.826)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbPniQxYj3vm",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlN7Z1n_x2cE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(list(range(1,10)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HfprJi3CKsN",
        "colab_type": "code",
        "outputId": "867324c2-b0fe-4a6d-cb95-36e93ab2f86a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''\n",
        "subs_df = pd.read_csv(\"submissions_data_train.zip\", compression='zip')\n",
        "print(subs_df.columns)\n",
        "print(subs_df.head())\n",
        "print(subs_df[0:500].groupby(['user_id', 'submission_status']).agg('count'))\n",
        "subset = subs_df.query('submission_status == \"wrong\"')\n",
        "print(subset.head())\n",
        "df1 = subset.groupby('step_id', as_index=False).agg({'submission_status': 'count'})\n",
        "print(df1.head())\n",
        "print(df1.sort_values(by=['submission_status'], ascending=False))\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nsubs_df = pd.read_csv(\"submissions_data_train.zip\", compression=\\'zip\\')\\nprint(subs_df.columns)\\nprint(subs_df.head())\\nprint(subs_df[0:500].groupby([\\'user_id\\', \\'submission_status\\']).agg(\\'count\\'))\\nsubset = subs_df.query(\\'submission_status == \"wrong\"\\')\\nprint(subset.head())\\ndf1 = subset.groupby(\\'step_id\\', as_index=False).agg({\\'submission_status\\': \\'count\\'})\\nprint(df1.head())\\nprint(df1.sort_values(by=[\\'submission_status\\'], ascending=False))\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3Qy8wt8F1Xe",
        "colab_type": "code",
        "outputId": "71df0757-30bb-4264-c457-b443153d3e76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''\n",
        "pd.set_option('display.max_columns', 500)\n",
        "subs_df = pd.read_csv(\"heart-disease-uci.zip\", compression='zip')\n",
        "print(subs_df.columns)\n",
        "print(subs_df.head())\n",
        "np.random.seed(0)\n",
        "rf = RandomForestClassifier(10, max_depth=5)\n",
        "x_train = subs_df.drop('target', axis=1)\n",
        "y_train = subs_df['target']\n",
        "rf.fit(x_train, y_train)\n",
        "imp = pd.DataFrame(rf.feature_importances_, index=x_train.columns, columns=['importance'])\n",
        "imp.sort_values('importance').plot(kind='barh', figsize=(12, 8))\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\npd.set_option(\\'display.max_columns\\', 500)\\nsubs_df = pd.read_csv(\"heart-disease-uci.zip\", compression=\\'zip\\')\\nprint(subs_df.columns)\\nprint(subs_df.head())\\nnp.random.seed(0)\\nrf = RandomForestClassifier(10, max_depth=5)\\nx_train = subs_df.drop(\\'target\\', axis=1)\\ny_train = subs_df[\\'target\\']\\nrf.fit(x_train, y_train)\\nimp = pd.DataFrame(rf.feature_importances_, index=x_train.columns, columns=[\\'importance\\'])\\nimp.sort_values(\\'importance\\').plot(kind=\\'barh\\', figsize=(12, 8))\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bMQb49LLRr0",
        "colab_type": "code",
        "outputId": "14858900-5970-4407-a972-09a5f4e2b5d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''\n",
        "rom sklearn.model_selection import GridSearchCV\n",
        "df = pd.read_csv(\"training_mush.csv\")\n",
        "print(subs_df.columns)\n",
        "print(subs_df.head())\n",
        "clf = RandomForestClassifier(random_state=0)\n",
        "params = {'n_estimators': range(10, 50, 10), 'max_depth': range(1, 12, 2), \\\n",
        "          'min_samples_leaf': range(1, 7, 1), 'min_samples_split': range(2, 9, 2)}\n",
        "x_train = df.drop('class', axis=1)\n",
        "y_train = df['class']\n",
        "search = GridSearchCV(clf, param_grid = params, n_jobs=-1, cv=3)\n",
        "search.fit(x_train, y_train)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nrom sklearn.model_selection import GridSearchCV\\ndf = pd.read_csv(\"training_mush.csv\")\\nprint(subs_df.columns)\\nprint(subs_df.head())\\nclf = RandomForestClassifier(random_state=0)\\nparams = {\\'n_estimators\\': range(10, 50, 10), \\'max_depth\\': range(1, 12, 2),           \\'min_samples_leaf\\': range(1, 7, 1), \\'min_samples_split\\': range(2, 9, 2)}\\nx_train = df.drop(\\'class\\', axis=1)\\ny_train = df[\\'class\\']\\nsearch = GridSearchCV(clf, param_grid = params, n_jobs=-1, cv=3)\\nsearch.fit(x_train, y_train)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKvfwfZhNoaE",
        "colab_type": "code",
        "outputId": "95dde899-34eb-4b51-d759-6268ccaf53fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''\n",
        "print(search.best_params_) \n",
        "imp = pd.DataFrame(search.best_estimator_.feature_importances_, index=x_train.columns, columns=['importance'])\n",
        "imp.sort_values('importance').plot(kind='barh', figsize=(12, 8))\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nprint(search.best_params_) \\nimp = pd.DataFrame(search.best_estimator_.feature_importances_, index=x_train.columns, columns=['importance'])\\nimp.sort_values('importance').plot(kind='barh', figsize=(12, 8))\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oe7_AfXUm8i",
        "colab_type": "code",
        "outputId": "843009c0-9a23-4027-f0ee-c5b4176b15c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''\n",
        "test_df = pd.read_csv(\"testing_mush.csv\")\n",
        "print(test_df.columns)\n",
        "print(test_df.head())\n",
        "predictions = DataFrame({'pred': search.best_estimator_.predict(test_df)})\n",
        "print(predictions['pred'].value_counts())\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ntest_df = pd.read_csv(\"testing_mush.csv\")\\nprint(test_df.columns)\\nprint(test_df.head())\\npredictions = DataFrame({\\'pred\\': search.best_estimator_.predict(test_df)})\\nprint(predictions[\\'pred\\'].value_counts())\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glBUZxC0V2lG",
        "colab_type": "code",
        "outputId": "9bde9c03-2b3c-43c5-92bb-6a43c240900b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''\n",
        "# ! unzip -P Cool!Move_forward! testing_y_mush.csv.zip\n",
        "from sklearn.metrics import confusion_matrix\n",
        "anot_df = pd.read_csv(\"testing_y_mush.csv\")\n",
        "print(anot_df.columns)\n",
        "print(anot_df.head())\n",
        "y_true = anot_df['class']\n",
        "y_pred = predictions['pred']\n",
        "sns.heatmap(confusion_matrix(y_true, y_pred), annot=True, cmap=\"Blues\")\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# ! unzip -P Cool!Move_forward! testing_y_mush.csv.zip\\nfrom sklearn.metrics import confusion_matrix\\nanot_df = pd.read_csv(\"testing_y_mush.csv\")\\nprint(anot_df.columns)\\nprint(anot_df.head())\\ny_true = anot_df[\\'class\\']\\ny_pred = predictions[\\'pred\\']\\nsns.heatmap(confusion_matrix(y_true, y_pred), annot=True, cmap=\"Blues\")\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHPM5T-saCnZ",
        "colab_type": "code",
        "outputId": "dfe6742d-c07d-46a6-d032-52d4fb12b6cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''\n",
        "train_df = pd.read_csv(\"invasion.csv\")\n",
        "print(train_df.columns)\n",
        "print(train_df.head())\n",
        "train_x = train_df.drop('class', axis=1)\n",
        "le = LabelEncoder()\n",
        "le.fit(train_df['class'])\n",
        "print(le.classes_)\n",
        "train_y = le.transform(train_df['class'])\n",
        "clf = RandomForestClassifier(random_state=0)\n",
        "params = {'n_estimators': range(10, 50, 10), 'max_depth': range(1, 12, 2), \\\n",
        "          'min_samples_leaf': range(1, 7, 1), 'min_samples_split': range(2, 9, 2)}\n",
        "search = GridSearchCV(clf, param_grid = params, n_jobs=-1, cv=5)\n",
        "search.fit(train_x, train_y)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ntrain_df = pd.read_csv(\"invasion.csv\")\\nprint(train_df.columns)\\nprint(train_df.head())\\ntrain_x = train_df.drop(\\'class\\', axis=1)\\nle = LabelEncoder()\\nle.fit(train_df[\\'class\\'])\\nprint(le.classes_)\\ntrain_y = le.transform(train_df[\\'class\\'])\\nclf = RandomForestClassifier(random_state=0)\\nparams = {\\'n_estimators\\': range(10, 50, 10), \\'max_depth\\': range(1, 12, 2),           \\'min_samples_leaf\\': range(1, 7, 1), \\'min_samples_split\\': range(2, 9, 2)}\\nsearch = GridSearchCV(clf, param_grid = params, n_jobs=-1, cv=5)\\nsearch.fit(train_x, train_y)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikXQnVpodeW-",
        "colab_type": "code",
        "outputId": "a2ffd61e-bf0d-4423-a37c-69526e95b0cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''\n",
        "test_df = pd.read_csv(\"operative_information.csv\")\n",
        "print(test_df.columns)\n",
        "print(test_df.head())\n",
        "predictions = search.best_estimator_.predict(test_df)\n",
        "out = pd.DataFrame({'ship_type': le.inverse_transform(predictions)})\n",
        "print(out['ship_type'].value_counts())\n",
        "print(search.best_estimator_.feature_importances_)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ntest_df = pd.read_csv(\"operative_information.csv\")\\nprint(test_df.columns)\\nprint(test_df.head())\\npredictions = search.best_estimator_.predict(test_df)\\nout = pd.DataFrame({\\'ship_type\\': le.inverse_transform(predictions)})\\nprint(out[\\'ship_type\\'].value_counts())\\nprint(search.best_estimator_.feature_importances_)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXVXP14IhiRV",
        "colab_type": "code",
        "outputId": "98172137-413e-4f11-9d57-f17a522252ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''\n",
        "train_df = pd.read_csv(\"space_can_be_a_dangerous_place.csv\")\n",
        "print(train_df.columns)\n",
        "print(train_df.head())\n",
        "print(train_df.corr())\n",
        "sns.heatmap(train_df.corr())\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ntrain_df = pd.read_csv(\"space_can_be_a_dangerous_place.csv\")\\nprint(train_df.columns)\\nprint(train_df.head())\\nprint(train_df.corr())\\nsns.heatmap(train_df.corr())\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uy1xVa5Wgz-Y",
        "colab_type": "code",
        "outputId": "17eb3094-7cf9-4c9c-9a4e-0405f97ab93b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "df = pd.read_csv(\"iris.csv\")\n",
        "from time import time\n",
        "before = time()\n",
        "df.apply(np.mean)\n",
        "after = time()\n",
        "print(after - before)\n",
        "before = time()\n",
        "df.mean(axis=0)\n",
        "after = time()\n",
        "print(after - before)\n",
        "before = time()\n",
        "df.describe().loc['mean']\n",
        "after = time()\n",
        "print(after - before)\n",
        "before = time()\n",
        "df.apply('mean')\n",
        "after = time()\n",
        "print(after - before)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0029287338256835938\n",
            "0.0005414485931396484\n",
            "0.02089858055114746\n",
            "0.001100301742553711\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mLwhmIMvEi2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pfgn6JgVa46y",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}